{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "848d3f5c",
   "metadata": {},
   "source": [
    "# Ensemble: Boosting\n",
    "\n",
    "- 다양한 모델을 결합하여 예측 성능을 향상시키는 방법\n",
    "    - 깊이가 얕은 결정트리를 사용해 이전 트리의 오차를 보정하는 방식\n",
    "    - 순차적으로 경사하강법을 사용해 이전 트리의 오차를 줄여나감\n",
    "        - 분류 모델에서는 손실함수 LogLoss를 사용해 오차를 줄임\n",
    "        - 회귀 모델에서는 손실함수 MSE를 사용해 오차를 줄임\n",
    "    - Boosting 계열은 일반적으로 결정트리 개수를 늘려도 과적합에 강함\n",
    "    - 대표 알고리즘(모델): GradientBoosting, HistGradientBoosting,  **XGBoost (DMLC)**,  LightGBM(MS), CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282b6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759b1d00",
   "metadata": {},
   "source": [
    "## GradientBoosting 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a388990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b1c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGradientBoostingClassifier:\n",
    "    def __init__(self, n_estimators=100, learning_rate = 0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.initial_log_odds = 0       # 초기 예측값\n",
    "        self.trees = []                 # 내부적으로 가지고 있는 estimator 모음 배열\n",
    "    \n",
    "    \n",
    "    def log_odds(self, p): # p: 확률값\n",
    "        # 확률값 -> 로짓변환 (컴큐터 더 편하게 할라고)\n",
    "        return np.log(p / (1-p)) \n",
    "    \n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        # z값 -> 0~1 사이의 확률 값 변환\n",
    "        return 1 /(1+np.exp(-z))\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        y_mean = np.mean(y) # 초기 예측값: 평균 (0과 1 다 더한 평균)\n",
    "        self.initial_log_odds = self.log_odds(y_mean)\n",
    "        y_pred_log_odds = np.full_like(y, self.initial_log_odds, dtype=np.float64)\n",
    "        \n",
    "        for _ in range(self.n_estimators): \n",
    "            y_pred_proba  = self.sigmoid(y_pred_log_odds)\n",
    "            residual = y - y_pred_proba # 이 잔차 값으로 학습을 진행함\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residual)\n",
    "            self.trees.append(tree)\n",
    "            y_pred_log_odds += self.learning_rate * tree.predict(X)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X) >= 0.5).astype(int) # boolean을 0 혹은 1로 변환\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        y_pred_log_odds = np.full((X.shape[0],), self.initial_log_odds) # 초기값 세팅\n",
    "        \n",
    "        for tree in self.trees:\n",
    "            y_pred_log_odds += self.learning_rate * tree.predict(X)\n",
    "        \n",
    "        return self.sigmoid(y_pred_log_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "715c4ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 정확도: 1.0\n",
      "평가 정확도: 0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=0)\n",
    "\n",
    "simple_gb_clf = SimpleGradientBoostingClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "simple_gb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = simple_gb_clf.predict(X_train)\n",
    "y_pred_test = simple_gb_clf.predict(X_test)\n",
    "\n",
    "print(f\"학습 정확도: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"평가 정확도: {accuracy_score(y_test, y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b086f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
